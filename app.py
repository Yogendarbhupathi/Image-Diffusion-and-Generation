# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JsZnXMGUm03wdaIsU0ZIFE6nJ0lcKuUT
"""

!pip install gradio

!pip install segment_anything

!pip install --upgrade diffusers

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
!pip install diffusers transformers accelerate
!pip install controlnet-aux gradio opencv-python

from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/controlnet_inpaint.py /content

!pip uninstall -y diffusers transformers accelerate
!pip install diffusers transformers accelerate --upgrade

import gradio as gr
import numpy as np
import torch
from diffusers import StableDiffusionInpaintPipeline
from PIL import Image, ImageOps, ImageEnhance
from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator
from diffusers import ControlNetModel
from diffusers import UniPCMultistepScheduler
from diffusers import StableDiffusionControlNetInpaintPipeline
import colorsys

sam_checkpoint = "/content/drive/MyDrive/sam_vit_h_4b8939.pth"
model_type = "vit_h"
device = "cuda" if torch.cuda.is_available() else "cpu"


sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)
predictor = SamPredictor(sam)
mask_generator = SamAutomaticMaskGenerator(sam)

controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-seg",
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
)
pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
)

pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe = pipe.to(device)


with gr.Blocks() as demo:
    gr.Markdown("Stable Diffusion + Segment Anything Model")
    gr.Markdown(
        """
    To try the demo, upload an image and select object(s) you want to inpaint.
    Write a prompt & a negative prompt to control the inpainting.
    Click on the "Submit" button to inpaint the selected object(s).
    Check "Background" to inpaint the background instead of the selected object(s).
    """
    )
    selected_pixels = gr.State([])
    with gr.Row():
        input_img = gr.Image(label="Input")
        mask_img = gr.Image(label="Mask", interactive=False)
        seg_img = gr.Image(label="Segmentation", interactive=False)
        output_img = gr.Image(label="Output", interactive=False)

    with gr.Row():
        prompt_text = gr.Textbox(lines=1, label="Prompt")
        negative_prompt_text = gr.Textbox(lines=1, label="Negative Prompt")
        is_background = gr.Checkbox(label="Background")

    with gr.Row():
        submit = gr.Button("Submit")
        clear = gr.Button("Clear")

    def generate_mask(image, bg, sel_pix, evt: gr.SelectData):
      sel_pix.append(evt.index)
      predictor.set_image(image)
      input_point = np.array(sel_pix)
      input_label = np.ones(input_point.shape[0])
      mask, _, _ = predictor.predict(
          point_coords=input_point,
          point_labels=input_label,
          multimask_output=False,
      )
      torch.cuda.empty_cache()

      if bg:
          mask = np.logical_not(mask)

      mask = Image.fromarray(mask[0, :, :])

      segs = mask_generator.generate(image)
      boolean_masks = [s["segmentation"] for s in segs]
      finseg = np.zeros((boolean_masks[0].shape[0], boolean_masks[0].shape[1], 3), dtype=np.uint8)

      for class_id, boolean_mask in enumerate(boolean_masks):
          hue = class_id * 1.0 / len(boolean_masks)
          rgb = tuple(int(i * 255) for i in colorsys.hsv_to_rgb(hue, 1, 1))
          rgb_mask = np.zeros((boolean_mask.shape[0], boolean_mask.shape[1], 3), dtype=np.uint8)
          rgb_mask[:, :, 0] = boolean_mask * rgb[0]
          rgb_mask[:, :, 1] = boolean_mask * rgb[1]
          rgb_mask[:, :, 2] = boolean_mask * rgb[2]
          finseg += rgb_mask

      torch.cuda.empty_cache()

      return mask, finseg


    def inpaint(image, mask, seg_img, prompt, negative_prompt, is_background):
        image = Image.fromarray(image)
        mask = Image.fromarray(mask)
        seg_img = Image.fromarray(seg_img)

        image = image.resize((512, 512))
        mask = mask.resize((512, 512))
        seg_img = seg_img.resize((512, 512))

        if is_background:
            mask = Image.fromarray(np.logical_not(np.array(mask)).convert("L"))

        output = pipe(
            prompt,
            image,
            mask,
            seg_img,
            negative_prompt=negative_prompt,
            num_inference_steps=90,
            guidance_scale=12.0,
        ).images[0]

        torch.cuda.empty_cache()

        return output

    def _clear(sel_pix, img, mask, seg, out, prompt, neg_prompt, bg):
        sel_pix = []
        img = None
        mask = None
        seg = None
        out = None
        prompt = ""
        neg_prompt = ""
        bg = False
        return img, mask, seg, out, prompt, neg_prompt, bg

    input_img.select(
        generate_mask,
        [input_img, is_background, selected_pixels],
        [mask_img, seg_img],
    )
    submit.click(
        inpaint,
        inputs=[input_img, mask_img, seg_img, prompt_text, negative_prompt_text],
        outputs=[output_img],
    )
    clear.click(
        _clear,
        inputs=[
            selected_pixels,
            input_img,
            mask_img,
            seg_img,
            output_img,
            prompt_text,
            negative_prompt_text,
            is_background,
        ],
        outputs=[
            input_img,
            mask_img,
            seg_img,
            output_img,
            prompt_text,
            negative_prompt_text,
            is_background,
        ],
    )

if __name__ == "__main__":
    demo.launch()

