The project aims at applying modern deep learning algorithms for the image inpainting capability that allows for changing certain areas of the image like backgrounds, faces, or clothes. This remarkable inpainting pipeline integrates Metaâ€™s Segment Anything Model together with the Hugging Face Diffusers library. With the help of Segmenting Model, the system enables one to select and modify definite parts of an image with the help of textual descriptions, which is possible due to accurate masking and segmentation. The following application is a strong and highly adjustable option that gives users with different degrees of skill sets potential to enhance image cleverness via through picture editing powers. 
The user interface is created through Gradio in order to present an easily navigable interface for the image inpainting tools. The primary feature is that selecting the pixels and creating masks and segmentations of such pixels become much easier for the users and are integrated into a single interface for editing. The project also investigates an improved inpainting pipe using tailored ControlNet implementation with better outcomes and featured additions such as segmentation blocks, backgrounds, and effective prompt management. The current version of segmentation model looks sleek, sensible and effective, proving the idea of using AI tools in creation and designing of the Image.

download the segment model from this link
https://drive.google.com/file/d/1XRk4WCcl9WymnciTgsr1j5dCGEdH2sTs/view?usp=drive_link
